\section*{Q2}

Subjectively, the translations chosen with p(e)=-1 are neither obviously worse or less fluent. They do, however seem to be longer. Since the longer the sentence the smaller the language model probability, it is to be expected that minimizing p(e) will favour longer outputs. For instance, the first example in table~\ref{translation_compare} shows sentences which arguably do not differ in content, although the second uses 10 words for what the first expresses in 3.

It seems that sometimes the preference for shortness leads to loss of information, e.g. in the second example. While both are good English, the flipped-LM one is closer to the reference translation which includes the phrase \textit{"this summer's tragedy"}. Similarily, in the third example the default translation simply omits the adjectives modifying \textit{language} and \textit{question}.

In some cases reversing the bias for language model probability leads to choosing more comprehensible translations, as seen in the next example in table~\ref{translation_compare}.

There are examples of LM likelihood value actually tracking what we'd like it to track, namely English fluency and idiomaticity. The last example in this section of table~\ref{translation_compare} shows an idiomatic expression \textit{keep in mind} being dealt with correctly by the default rearnker